# ðŸ§  GuÃ­a Completa de Entrenamiento - Desde Web Contributions hasta Modelo Final

**GuÃ­a paso a paso para procesar contribuciones web y entrenar modelos LSTM con normalizaciÃ³n**

---

## ðŸ“‹ Resumen del Flujo

```
1. Descargar Contribuciones Web (Google Drive)
   â†“
2. Convertir JSON â†’ .npy
   â†“
3. Calcular EstadÃ­sticas de NormalizaciÃ³n â­ IMPORTANTE
   â†“
4. Entrenar Modelo (Node.js v6 o Python v2)
   â†“
5. Modelo Listo para Uso
```

---

## ðŸš€ Paso 1: Descargar Contribuciones Web

Las contribuciones vienen desde el frontend web y se almacenan en Google Drive.

### OpciÃ³n A: Desde Google Drive (Recomendado)

```bash
cd gesto_releasev1
node scripts/download_from_drive.js
```

**ConfiguraciÃ³n:**
- Credenciales: `unavoz-bb3744af7f68.json` (en la raÃ­z)
- Service Account: `unavoz@unavoz.iam.gserviceaccount.com`
- Folder ID: `1zkP5QPXCZU1nM2hL11r6VIzK0053yNtb`

**Salida esperada:**
```
ðŸ” Autenticando con Google Drive...
ðŸ“¥ Descargando archivos...
âœ… Descarga completa: 100 archivos
```

**Archivos guardados en:** `assets/web_contributions/*.json`

### OpciÃ³n B: Desde Frontend Local

Si tienes el frontend corriendo localmente, los archivos estÃ¡n en:
```
sign-language-interpreter-frontend/captured_samples/*.json
```

---

## ðŸ”„ Paso 2: Convertir JSON â†’ .npy

Convierte las contribuciones web a formato .npy para entrenamiento:

```bash
# Si las contribuciones estÃ¡n en assets/web_contributions/
python scripts/convert_frontend_samples_to_npy.py assets/web_contributions

# O desde el directorio del frontend
python scripts/convert_frontend_samples_to_npy.py ../../sign-language-interpreter-frontend
```

**Proceso:**
- âœ… Lee todos los JSON del directorio
- âœ… Agrupa por gesto
- âœ… Normaliza a 15 frames (padding o muestreo uniforme)
- âœ… Guarda como `.npy` en `assets/data/keypoints/`
- âœ… Actualiza `models/words.json` con los gestos encontrados

**Salida esperada:**
```
ðŸŒ Conversor: Frontend Samples â†’ NumPy

ðŸ“Š Total de archivos: 100
âœ… Muestras vÃ¡lidas: 100

ðŸ“‹ Resumen por gesto:
   - hola: 15 muestras
   - bien: 12 muestras
   - gracias: 18 muestras
   ...

ðŸ“¦ Procesando gestos...
âœ… ConversiÃ³n completada
```

**Archivos generados:**
```
assets/data/keypoints/
â”œâ”€â”€ hola.npy
â”œâ”€â”€ bien.npy
â”œâ”€â”€ gracias.npy
â””â”€â”€ ...
```

---

## ðŸ“Š Paso 3: Calcular EstadÃ­sticas de NormalizaciÃ³n â­ IMPORTANTE

**Este paso es CRÃTICO** para un buen entrenamiento. Calcula las estadÃ­sticas necesarias para normalizar los datos:

```bash
python src/calculate_normalization_stats.py
```

**Â¿Por quÃ© normalizar?**
- âœ… Mejora la convergencia del modelo
- âœ… Reduce el tiempo de entrenamiento
- âœ… Mejora la precisiÃ³n final
- âœ… Normaliza por componente (Pose, Face, Hands)

**Salida esperada:**
```
ðŸ“Š Calculando estadÃ­sticas de normalizaciÃ³n...

ðŸ“ Procesando archivos .npy en: assets/data/keypoints
âœ… Archivos encontrados: 18

ðŸ“Š Calculando estadÃ­sticas por componente:
   - Pose: 132 keypoints
   - Face: 1404 keypoints
   - Left Hand: 63 keypoints
   - Right Hand: 63 keypoints

âœ… EstadÃ­sticas guardadas en: models/normalization_stats.json
```

**Archivo generado:**
```
models/normalization_stats.json
```

**âš ï¸ IMPORTANTE:** Este paso debe ejecutarse ANTES de entrenar. El entrenador lo requiere.

---

## ðŸ§  Paso 4: Entrenar Modelo

Ahora puedes entrenar usando cualquiera de los dos trainers disponibles.

---

### ðŸŒ OpciÃ³n A: Node.js v6 (Recomendado para Web)

**Trainer:** `src/train_lstm_node_v6.js`

#### InstalaciÃ³n

```bash
npm install
```

#### EjecuciÃ³n

```bash
# Auto-detecciÃ³n de backend (GPU â†’ CPU â†’ JS)
node src/train_lstm_node_v6.js

# Forzar GPU (si tienes NVIDIA + cuDNN)
node src/train_lstm_node_v6.js --gpu

# Forzar CPU (acelerado con TensorFlow C++)
node src/train_lstm_node_v6.js --cpu

# Forzar JavaScript puro (mÃ¡s lento)
node src/train_lstm_node_v6.js --js
```

#### Arquitectura del Modelo

```
Input: [batch, 15 frames, 1662 keypoints]
   â†“
LSTM(256) + Dropout(0.3) + BatchNorm
   â†“
LSTM(128) + Dropout(0.3) + BatchNorm
   â†“
Dense(32, ReLU) + Dropout(0.3)
   â†“
Dense(num_classes, Softmax)
```

**ParÃ¡metros optimizados (TOP 1 Grid Search):**
- LSTM 1: 256 units
- LSTM 2: 128 units
- Dense: 32 units
- Dropout: 0.3
- Recurrent Dropout: 0.2
- L2 Regularization: 0.001
- Learning Rate: 0.0001
- Batch Size: 32

#### Salida Esperada

```
ðŸ§  Entrenamiento LSTM v6.0 - ParÃ¡metros Optimizados

ðŸ“‹ Gestos: 18
ðŸ“Š DistribuciÃ³n estratificada por gesto:
   hola: Train=50, Val=15, Test=8 (Total=73)
   bien: Train=45, Val=13, Test=7 (Total=65)
   ...

ðŸ—ï¸  Construyendo modelo LSTM v6.0...
   Arquitectura: LSTM[256, 128] â†’ Dense[32] â†’ Softmax[18]

ðŸš€ Iniciando entrenamiento...

Epoch 125/200
loss: 0.239 - acc: 0.979 - val_loss: 0.047 - val_acc: 0.995

â¹ï¸  EARLY STOPPING ACTIVADO
   Mejor val_loss: 0.0467 (epoch 125)

ðŸ“Š Evaluando modelo en conjunto de prueba...
âœ… Test Accuracy: 97.94%

ðŸ’¾ Guardando modelo...
âœ… Modelo guardado en: models/modelo_tfjs_node
âœ… Matriz de confusiÃ³n guardada en: models/confusion_matrix_v6.json
âœ… Reporte guardado en: models/training_report_v6.json
```

#### Archivos Generados

```
models/
â”œâ”€â”€ modelo_tfjs_node/
â”‚   â”œâ”€â”€ model.json              # Arquitectura del modelo
â”‚   â”œâ”€â”€ weights.bin             # Pesos del modelo
â”‚   â””â”€â”€ words.json              # Etiquetas de gestos
â”œâ”€â”€ normalization_stats.json     # EstadÃ­sticas (ya existente)
â”œâ”€â”€ training_report_v6.json     # Reporte completo de entrenamiento
â””â”€â”€ confusion_matrix_v6.json    # Matriz de confusiÃ³n
```

---

### ðŸ OpciÃ³n B: Python v2 (Recomendado para GPU)

**Trainer:** `src/train_lstm_actions_v2.py`

#### InstalaciÃ³n

```bash
# Crear entorno virtual
python -m venv env
source env/bin/activate  # Linux/Mac
.\env\Scripts\Activate.ps1  # Windows

# Instalar dependencias
pip install -r requirements_v2.txt
```

#### EjecuciÃ³n

```bash
python src/train_lstm_actions_v2.py
```

El script detecta automÃ¡ticamente GPU si estÃ¡ disponible.

#### Arquitectura del Modelo

Igual que Node.js v6 (mismos parÃ¡metros optimizados).

#### Salida Esperada

```
ðŸ§  Entrenamiento de LSTM para reconocimiento de gestos en Python
VERSIÃ“N v2.0

ðŸš€ GPU detectada y configurada para uso
ðŸ“‹ Gestos: 18

ðŸ“Š Evaluando modelo...
âœ… Test Accuracy: 97.94%

ðŸ“Š INFORME DETALLADO POR GESTO
   - MÃ©tricas por gesto (precision, recall, F1)
   - Matriz de confusiÃ³n
   - AnÃ¡lisis de rendimiento

ðŸ’¾ Informe guardado en: models/training_report.json
âœ… Modelo Keras guardado en: models/actions_15.keras
âœ… Modelo exportado a: models/modelo_tfjs_node/
```

#### Archivos Generados

```
models/
â”œâ”€â”€ actions_15.keras            # Modelo Keras (solo Python)
â”œâ”€â”€ modelo_tfjs_node/           # Modelo TensorFlow.js
â”‚   â”œâ”€â”€ model.json
â”‚   â”œâ”€â”€ weights.bin
â”‚   â””â”€â”€ words.json
â””â”€â”€ training_report.json        # Reporte completo
```

---

## ðŸ“Š Paso 5: Verificar Resultados

### Reporte de Entrenamiento

Ambos trainers generan reportes detallados:

**Node.js v6:** `models/training_report_v6.json`
**Python v2:** `models/training_report.json`

**Contenido del reporte:**
- MÃ©tricas generales (accuracy, loss)
- MÃ©tricas por gesto (precision, recall, F1, support)
- Historial de entrenamiento
- Matriz de confusiÃ³n (solo Node.js v6)

### Matriz de ConfusiÃ³n

Solo Node.js v6 genera: `models/confusion_matrix_v6.json`

```json
{
  "version": "v6.0",
  "gestures": ["hola", "bien", ...],
  "matrix": [[...], [...]]
}
```

---

## ðŸ”§ ConfiguraciÃ³n Avanzada

### Ajustar ParÃ¡metros de Entrenamiento

#### Node.js v6

Edita `src/train_lstm_node_v6.js`:

```javascript
const CONFIG = {
  EPOCHS: 200,
  BATCH_SIZE: 32,
  LEARNING_RATE: 0.0001,
  VALIDATION_SPLIT: 0.2,
  TEST_SPLIT: 0.1,
  EARLY_STOPPING_PATIENCE: 10,
};
```

#### Python v2

Edita `src/train_lstm_actions_v2.py`:

```python
EPOCHS = 200
BATCH_SIZE = 32
LEARNING_RATE = 0.0001
VALIDATION_SPLIT = 0.2
```

---

## ðŸ› SoluciÃ³n de Problemas

### Error: "Archivo de normalizaciÃ³n no encontrado"

**SoluciÃ³n:**
```bash
# Ejecutar paso 3 primero
python src/calculate_normalization_stats.py
```

### Support muy bajo en test

**Causa:** DivisiÃ³n no estratificada (solo en versiones antiguas)

**SoluciÃ³n:** Node.js v6 ya usa split estratificado automÃ¡ticamente.

### Entrenamiento muy lento (Node.js)

**Soluciones:**
1. Instalar `@tensorflow/tfjs-node` para aceleraciÃ³n CPU
2. Instalar `@tensorflow/tfjs-node-gpu` para GPU (requiere cuDNN)
3. Usar Python v2 con GPU (mÃ¡s rÃ¡pido)

### GPU no funciona (Python)

**Verificar:**
```bash
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
```

**Si no aparece GPU:**
1. Verificar CUDA instalado: `nvidia-smi`
2. Reinstalar TensorFlow con soporte GPU:
   ```bash
   pip install tensorflow[and-cuda]
   ```

---

## ðŸ“ˆ MÃ©tricas de Calidad

### Dataset Saludable

```
âœ… MÃ­nimo 30 muestras por gesto
âœ… Total: 500+ muestras
âœ… Balance: Â±20% entre clases
âœ… NormalizaciÃ³n aplicada
```

### Modelo Entrenado

```
âœ… Test accuracy > 95%
âœ… Validation accuracy > 90%
âœ… Loss decreciente y estable
âœ… No overfitting (gap train/val < 10%)
âœ… Support equilibrado en test (split estratificado)
```

---

## ðŸŽ¯ Workflow Completo (Resumen)

```bash
# 1. Descargar contribuciones web
node scripts/download_from_drive.js

# 2. Convertir JSON â†’ .npy
python scripts/convert_frontend_samples_to_npy.py assets/web_contributions

# 3. Calcular estadÃ­sticas de normalizaciÃ³n
python src/calculate_normalization_stats.py

# 4a. Entrenar con Node.js v6
npm install
node src/train_lstm_node_v6.js

# O 4b. Entrenar con Python v2
pip install -r requirements_v2.txt
python src/train_lstm_actions_v2.py

# 5. Verificar resultados
# Revisar: models/training_report_v6.json o models/training_report.json
```

---

## ðŸ“š Referencias

- [TensorFlow.js](https://www.tensorflow.org/js)
- [Keras](https://keras.io/)
- [MediaPipe Holistic](https://google.github.io/mediapipe/solutions/holistic.html)

---

**Ãšltima actualizaciÃ³n**: Noviembre 2025  
**VersiÃ³n**: v6.0  
**Estado**: ProducciÃ³n âœ…
